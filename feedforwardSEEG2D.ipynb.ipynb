{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "TrainSet = np.loadtxt('C:/EEGProblem/DNN/pytorch_udemy/data/train_data.csv',dtype=np.float32,delimiter=',')\n",
    "TrainSet = torch.from_numpy(TrainSet)\n",
    "print(TrainSet.shape[0])\n",
    "                        \n",
    "TrainLabels = np.loadtxt('C:/EEGProblem/DNN/pytorch_udemy/data/train_labels.csv',dtype=np.float32,delimiter=',') \n",
    "TrainLabels = torch.from_numpy(TrainLabels)\n",
    "\n",
    "TestSet = np.loadtxt('C:/EEGProblem/DNN/pytorch_udemy/data/test_data.csv',dtype=np.float32,delimiter=',')\n",
    "TestSet = torch.from_numpy(TestSet)\n",
    "print(TrainSet.shape[0])\n",
    "                        \n",
    "TestLabels = np.loadtxt('C:/EEGProblem/DNN/pytorch_udemy/data/test_labels.csv',dtype=np.float32,delimiter=',') \n",
    "TestLabels = torch.from_numpy(TestLabels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 1 50\n"
     ]
    }
   ],
   "source": [
    "BatchSize = 500;\n",
    "NumWindow = 1;\n",
    "NumIters = 5000;\n",
    "NumEpochs = int(NumIters/(len(TrainSet)/BatchSize));\n",
    "print(BatchSize,NumWindow,TestSet.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2000, 1000])\n"
     ]
    }
   ],
   "source": [
    "TrainLoader = torch.utils.data.DataLoader(dataset = TrainSet,\n",
    "                                    batch_size = BatchSize,\n",
    "                                    shuffle = False);\n",
    "print(TrainLoader.dataset.shape)                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "LabelLoader = torch.utils.data.DataLoader(dataset = TrainLabels,\n",
    "                                        batch_size = BatchSize,\n",
    "                                        shuffle = False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardModel(nn.Module):\n",
    "    def __init__(self,InputSize,HiddenSize1,HiddenSize2,HiddenSize3,HiddenDim4,HiddenDim5,HiddenDim6,\n",
    "                 HiddenDim7,OutputSize):\n",
    "        super(FeedForwardModel,self).__init__()\n",
    "        self.fc1 = nn.Linear(InputDim,HiddenDim1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(HiddenDim1,HiddenDim2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(HiddenDim2,HiddenDim3)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc4 = nn.Linear(HiddenDim3,HiddenDim4)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.fc5 = nn.Linear(HiddenDim4,HiddenDim5)\n",
    "        self.relu5 = nn.ReLU()\n",
    "        self.fc6 = nn.Linear(HiddenDim5,HiddenDim6)\n",
    "        self.relu6 = nn.ReLU()\n",
    "        self.fc7 = nn.Linear(HiddenDim6,HiddenDim7)\n",
    "        self.relu7 = nn.ReLU()        \n",
    "        self.fc8 = nn.Linear(HiddenDim7,OutputDim)\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        output = self.fc1(x)\n",
    "        output = self.relu1(output)\n",
    "        output = self.fc2(output)\n",
    "        output = self.relu2(output)\n",
    "        output = self.fc3(output)\n",
    "        output = self.relu3(output)        \n",
    "        output = self.fc4(output)\n",
    "        output = self.relu4(output)        \n",
    "        output = self.fc5(output)\n",
    "        output = self.relu5(output)        \n",
    "        output = self.fc6(output)    \n",
    "        output = self.relu6(output)  \n",
    "        output = self.fc7(output)    \n",
    "        output = self.relu7(output)    \n",
    "        output = self.fc8(output)                              \n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "InputDim = TrainSet.shape[0];\n",
    "OutputDim = TrainLabels.shape[0];\n",
    "HiddenDim1 = 50; \n",
    "HiddenDim2 = 50;\n",
    "HiddenDim3 = 50;\n",
    "HiddenDim4 = 50; \n",
    "HiddenDim5 = 50;\n",
    "HiddenDim6 = 50;\n",
    "HiddenDim7 = 50;\n",
    "\n",
    "\n",
    "\n",
    "model = FeedForwardModel(InputDim,HiddenDim1,HiddenDim2,HiddenDim3,HiddenDim4,HiddenDim5,HiddenDim6,\n",
    "                 HiddenDim7,OutputDim);\n",
    "criterion = nn.MSELoss();\n",
    "\n",
    "\n",
    "\n",
    "learningrate = 0.000001;\n",
    "optimizer = torch.optim.ASGD(model.parameters(), lr = learningrate,lambd=0, alpha=0.95, t0=10000.0, weight_decay=0.000001)\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr = learningrate,weight_decay=0.00001);\n",
    "#optimizer = torch.optim.ASGD(model.parameters(),lr=learningrate,)\n",
    "Iter = 0;\n",
    "error = 0;\n",
    "testsize = TestSet.shape[1]\n",
    "print(testsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 10100 loss 0.08205493539571762 error 2.360386610031128 \n",
      "iter 10200 loss 0.08169858902692795 error 2.3593976497650146 \n",
      "iter 10300 loss 0.0813513994216919 error 2.358436107635498 \n",
      "iter 10400 loss 0.08101191371679306 error 2.357499599456787 \n",
      "iter 10500 loss 0.08067986369132996 error 2.3565866947174072 \n",
      "iter 10600 loss 0.0803551897406578 error 2.3556976318359375 \n",
      "iter 10700 loss 0.08003807812929153 error 2.354832649230957 \n",
      "iter 10800 loss 0.07972756773233414 error 2.3539888858795166 \n",
      "iter 10900 loss 0.07942402362823486 error 2.3531689643859863 \n",
      "iter 11000 loss 0.07912562042474747 error 2.3523685932159424 \n",
      "iter 11100 loss 0.07883353531360626 error 2.3515870571136475 \n",
      "iter 11200 loss 0.07854762673377991 error 2.3508265018463135 \n",
      "iter 11300 loss 0.07826778292655945 error 2.350085496902466 \n",
      "iter 11400 loss 0.07799383252859116 error 2.3493640422821045 \n",
      "iter 11500 loss 0.07772556692361832 error 2.348663091659546 \n",
      "iter 11600 loss 0.07746431976556778 error 2.3479843139648438 \n",
      "iter 11700 loss 0.07720913738012314 error 2.347325086593628 \n",
      "iter 11800 loss 0.07696010917425156 error 2.3466875553131104 \n",
      "iter 11900 loss 0.0767175629734993 error 2.3460710048675537 \n",
      "iter 12000 loss 0.0764811709523201 error 2.3454747200012207 \n",
      "iter 12100 loss 0.07625103741884232 error 2.3448989391326904 \n",
      "iter 12200 loss 0.07602770626544952 error 2.3443474769592285 \n",
      "iter 12300 loss 0.0758102536201477 error 2.343815803527832 \n",
      "iter 12400 loss 0.07559851557016373 error 2.3433024883270264 \n",
      "iter 12500 loss 0.07539267092943192 error 2.342808723449707 \n",
      "iter 12600 loss 0.0751945823431015 error 2.342341423034668 \n",
      "iter 12700 loss 0.07500259578227997 error 2.341895341873169 \n",
      "iter 12800 loss 0.07481689751148224 error 2.341470718383789 \n",
      "iter 12900 loss 0.07463743537664413 error 2.3410661220550537 \n",
      "iter 13000 loss 0.07446540147066116 error 2.340686321258545 \n",
      "iter 13100 loss 0.0743003860116005 error 2.340330123901367 \n",
      "iter 13200 loss 0.0741417333483696 error 2.339996099472046 \n",
      "iter 13300 loss 0.07398934662342072 error 2.3396823406219482 \n",
      "iter 13400 loss 0.07384379953145981 error 2.3393921852111816 \n",
      "iter 13500 loss 0.07370518893003464 error 2.3391242027282715 \n",
      "iter 13600 loss 0.07357514649629593 error 2.338886260986328 \n",
      "iter 13700 loss 0.07345285266637802 error 2.3386733531951904 \n",
      "iter 13800 loss 0.0733351781964302 error 2.338477849960327 \n",
      "iter 13900 loss 0.07322373241186142 error 2.33830189704895 \n",
      "iter 14000 loss 0.07312007248401642 error 2.338151693344116 \n",
      "iter 14100 loss 0.07301920652389526 error 2.338009834289551 \n",
      "iter 14200 loss 0.07292120158672333 error 2.337876558303833 \n",
      "iter 14300 loss 0.07282550632953644 error 2.3377487659454346 \n",
      "iter 14400 loss 0.07273230701684952 error 2.3376271724700928 \n",
      "iter 14500 loss 0.07264602929353714 error 2.337524890899658 \n",
      "iter 14600 loss 0.0725623145699501 error 2.3374292850494385 \n",
      "iter 14700 loss 0.07247978448867798 error 2.3373351097106934 \n",
      "iter 14800 loss 0.07239866256713867 error 2.337242841720581 \n",
      "iter 14900 loss 0.07231897115707397 error 2.3371522426605225 \n",
      "iter 15000 loss 0.0722406655550003 error 2.3370633125305176 \n"
     ]
    }
   ],
   "source": [
    "#if torch.cuda.is_available():\n",
    "#    model.cuda()\n",
    "for iw in range(int(NumWindow)):\n",
    "  for iter in range(NumIters):\n",
    "    for i in range((iw-1)*BatchSize,iw*BatchSize):\n",
    "      #print(len(TrainLabels[:,i]))\n",
    "      images = Variable(TrainSet[:,i]); # size of (batchsize, n1*n2), so there will be batchsize number of images each of size n1*n2;\n",
    "      labels = Variable(TrainLabels[:,i]); # size of ten, labels 0 to 9\n",
    "#      if torch.cuda.is_available():\n",
    "#        images = Variable(TrainSet[:,i].cuda()); # size of (batchsize, n1*n2), so there will be batchsize number of images each of size n1*n2;\n",
    "#        labels = Variable(TrainLabels[:,i].cuda()); \n",
    "      optimizer.zero_grad();\n",
    "      outputs = model(images);  # each image is assigned a probability table w.r.f the labels, so there are ten probability assigned to each image, wrt labels 0 to 9.\n",
    "\n",
    "      loss = criterion(outputs,labels);\n",
    "      loss.backward();\n",
    "      optimizer.step()\n",
    "    Iter += 1;\n",
    "    if Iter%100 == 0:          \n",
    "      for i in range(testsize):\n",
    "        predicted = model(TestSet[:,i]) \n",
    "        error += torch.norm(predicted - TestLabels[:,i]);  \n",
    "      error = error/testsize\n",
    "      print('iter {} loss {} error {} '.format(Iter,loss.item(),error)) \n",
    "  \n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0317,  0.0263, -0.0167,  0.0255,  0.1460,  0.1489,  0.1471,  0.1667,\n",
      "         0.6339,  0.6383,  0.6406,  0.6712], grad_fn=<AddBackward0>)\n",
      "tensor([-0.2324, -1.1853,  0.4875,  0.9302,  0.3120,  0.2398,  0.1816,  0.0893,\n",
      "         0.7200,  0.7037,  0.7181,  0.7093])\n",
      "[0.62710285 0.63128436 0.6336851  0.661876  ] [0.68524617 0.683569   0.7062778  0.7064562 ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "   \n",
    "poolidx = 32\n",
    "#model.cpu()\n",
    "predicted = model(TestSet[:,poolidx])   \n",
    "#if torch.cuda.is_available():\n",
    "#    predicted.cpu()\n",
    "print(predicted)   \n",
    "print(TestLabels[:,poolidx])     \n",
    "\n",
    "prediction = predicted.data.numpy()\n",
    "groundtruth = TestLabels[:,poolidx].data.numpy()\n",
    "N_Source = int(len(prediction)/3)\n",
    "\n",
    "Intensity = prediction[0:N_Source]\n",
    "Theta = prediction[N_Source:2*N_Source]\n",
    "Radii = prediction[2*N_Source:3*N_Source]\n",
    "\n",
    "Intensity_Truth = groundtruth[0:N_Source]\n",
    "Theta_Truth = groundtruth[N_Source:2*N_Source]\n",
    "Radii_Truth = groundtruth[2*N_Source:3*N_Source]\n",
    "\n",
    "x_loc = Radii*np.cos(Theta)\n",
    "y_loc = Radii*np.sin(Theta)\n",
    "x_loc_truth = Radii_Truth*np.cos(Theta_Truth)\n",
    "y_loc_truth = Radii_Truth*np.sin(Theta_Truth)\n",
    "\n",
    "print(x_loc,x_loc_truth)\n",
    "plt.scatter(x_loc,y_loc,marker=\"o\")\n",
    "plt.scatter(x_loc_truth,y_loc_truth,marker=\".\")\n",
    "PATH = 'C:/EEGProblem/DNN/pytorch_udemy/data/eegmodel2'\n",
    "torch.save(model, 'C:/EEGProblem/DNN/pytorch_udemy/data/eegmodel2')\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1f655910e3c530d546b842111bc404decc94f6ba58cc93acd17b2fc442a5408d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
